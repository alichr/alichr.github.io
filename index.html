<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Ali Cheraghian | AI Researcher â€” 27 publications at CVPR, ICCV, ECCV, ICLR (930+ citations). Expert in vision-language models, knowledge distillation, and 3D point cloud understanding.">
    <meta name="keywords" content="Ali Cheraghian, AI, Machine Learning, Computer Vision, Deep Learning, Research Scientist, Macquarie University, CVPR, ICCV, ECCV">
    <meta name="author" content="Ali Cheraghian">
    <meta name="theme-color" content="#002b5e" id="theme-color-meta">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="Ali Cheraghian - Senior AI/ML Scientist">
    <meta property="og:description" content="Senior AI/ML Scientist at Macquarie University. Research in Vision-Language Models, LLMs, Knowledge Distillation, and 3D Point Cloud Understanding.">
    <meta property="og:image" content="https://alichr.github.io/images/profile.webp">
    <meta property="og:url" content="https://alichr.github.io">
    <meta property="og:site_name" content="Ali Cheraghian">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Ali Cheraghian - Senior AI/ML Scientist">
    <meta name="twitter:description" content="Senior AI/ML Scientist at Macquarie University. Research in Vision-Language Models, LLMs, and Computer Vision.">
    <meta name="twitter:image" content="https://alichr.github.io/images/profile.webp">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ðŸŽ“</text></svg>">
    <link rel="apple-touch-icon" href="./images/profile.webp">

    <link rel="canonical" href="https://alichr.github.io/">
    <title>Ali Cheraghian - Senior AI/ML Scientist</title>

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Person",
        "name": "Ali Cheraghian",
        "jobTitle": "Senior AI/ML Scientist",
        "affiliation": {
            "@type": "Organization",
            "name": "Macquarie University"
        },
        "alumniOf": [
            {
                "@type": "Organization",
                "name": "Australian National University"
            },
            {
                "@type": "Organization",
                "name": "Amirkabir University of Technology"
            }
        ],
        "url": "https://alichr.github.io",
        "image": "https://alichr.github.io/images/profile.webp",
        "sameAs": [
            "https://www.linkedin.com/in/ali-cheraghian/",
            "https://github.com/alichr",
            "https://scholar.google.com/citations?user=QT0EXIkAAAAJ"
        ],
        "knowsAbout": ["Computer Vision", "Machine Learning", "Vision-Language Models", "Knowledge Distillation", "3D Point Clouds"]
    }
    </script>
    <script type="application/ld+json">
    [{
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "name": "Semantic-Aware Knowledge Distillation for Few-Shot Class-Incremental Learning",
        "author": [{"@type": "Person", "name": "Ali Cheraghian"}, {"@type": "Person", "name": "Shafin Rahman"}, {"@type": "Person", "name": "Pengfei Fang"}, {"@type": "Person", "name": "Soumava Kumar Roy"}, {"@type": "Person", "name": "Lars Petersson"}, {"@type": "Person", "name": "Mehrtash Harandi"}],
        "datePublished": "2021",
        "publisher": {"@type": "Organization", "name": "CVPR"},
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf"
    },
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "name": "Synthesized Feature Based Few-Shot Class-Incremental Learning on a Mixture of Subspaces",
        "author": [{"@type": "Person", "name": "Ali Cheraghian"}, {"@type": "Person", "name": "Shafin Rahman"}, {"@type": "Person", "name": "Sameera Ramasinghe"}, {"@type": "Person", "name": "Pengfei Fang"}, {"@type": "Person", "name": "Christian Simon"}, {"@type": "Person", "name": "Lars Petersson"}],
        "datePublished": "2021",
        "publisher": {"@type": "Organization", "name": "ICCV"},
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Cheraghian_Synthesized_Feature_Based_Few-Shot_Class-Incremental_Learning_on_a_Mixture_of_ICCV_2021_paper.pdf"
    },
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "name": "Backpropagation-free Network for 3D Test-time Adaptation",
        "author": [{"@type": "Person", "name": "Yanshuo Wang"}, {"@type": "Person", "name": "Ali Cheraghian"}, {"@type": "Person", "name": "Zeeshan Hayder"}, {"@type": "Person", "name": "Jie Hong"}, {"@type": "Person", "name": "Sameera Ramasinghe"}, {"@type": "Person", "name": "Shafin Rahman"}],
        "datePublished": "2024",
        "publisher": {"@type": "Organization", "name": "CVPR"},
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Backpropagation-free_Network_for_3D_Test-time_Adaptation_CVPR_2024_paper.pdf"
    },
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "name": "Canonical Shape Projection is All You Need for 3D Few-Shot Class Incremental Learning",
        "author": [{"@type": "Person", "name": "Ali Cheraghian"}, {"@type": "Person", "name": "Zeeshan Hayder"}, {"@type": "Person", "name": "Sameera Ramasinghe"}, {"@type": "Person", "name": "Shafin Rahman"}, {"@type": "Person", "name": "Javad Jafaryahya"}],
        "datePublished": "2024",
        "publisher": {"@type": "Organization", "name": "ECCV"},
        "url": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05717.pdf"
    },
    {
        "@context": "https://schema.org",
        "@type": "ScholarlyArticle",
        "name": "DTO-KD: Dynamic Trade-off Optimization for Effective Knowledge Distillation",
        "author": [{"@type": "Person", "name": "Zeeshan Hayder"}, {"@type": "Person", "name": "Ali Cheraghian"}, {"@type": "Person", "name": "Lars Petersson"}, {"@type": "Person", "name": "Mehrtash Harandi"}, {"@type": "Person", "name": "Richard Hartley"}],
        "datePublished": "2026",
        "publisher": {"@type": "Organization", "name": "ICLR"}
    }]
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/chart.js" defer></script>
    <script>
        // Prevent flash of wrong theme
        (function() {
            const savedTheme = localStorage.getItem('theme');
            const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;

            if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
                document.documentElement.classList.add('dark-mode');
            }
        })();
    </script>
</head>

<body>
    <!-- Skip Link for Accessibility -->
    <a href="#main-content" class="skip-link">Skip to main content</a>

    <header role="banner">
        <div class="header-content">
            <!-- Dark Mode Toggle -->
            <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode" type="button">
                <span class="sun-icon" aria-hidden="true">&#9728;</span>
                <span class="moon-icon" aria-hidden="true">&#9790;</span>
            </button>

            <div class="hero-layout">
                <img src="./images/profile.webp" alt="Ali Cheraghian - Profile Photo" class="profile-photo" width="200" height="200" fetchpriority="high">
                <div class="hero-text">
                    <h1>Ali Cheraghian</h1>
                    <p class="title">Senior AI/ML Scientist | Macquarie University</p>
                    <p class="hero-tagline">My research focuses on enabling AI models to generalize from limited supervision &mdash; spanning vision-language understanding, knowledge distillation, 3D point cloud analysis, and test-time adaptation, with publications at CVPR, ICCV, ECCV, ICLR, IJCV, TMLR, and Pattern Recognition.</p>

                    <div class="hero-metrics" aria-label="Citation metrics">
                        <a href="https://scholar.google.com/citations?user=QT0EXIkAAAAJ" target="_blank" rel="noopener noreferrer" class="metric-badge">
                            <span class="metric-value">930+</span>
                            <span class="metric-label">Citations</span>
                        </a>
                        <a href="https://scholar.google.com/citations?user=QT0EXIkAAAAJ" target="_blank" rel="noopener noreferrer" class="metric-badge">
                            <span class="metric-value">12</span>
                            <span class="metric-label">h-index</span>
                        </a>
                        <span class="metric-badge">
                            <span class="metric-value">27</span>
                            <span class="metric-label">Papers</span>
                        </span>
                    </div>

                    <nav class="contact-links" role="navigation" aria-label="Contact and social links">
                        <a href="mailto:ali.cheraghian@mq.edu.au" aria-label="Send email to Ali Cheraghian" class="social-link">
                            <svg class="social-icon" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M1.5 8.67v8.58a3 3 0 003 3h15a3 3 0 003-3V8.67l-8.928 5.493a3 3 0 01-3.144 0L1.5 8.67z"/><path d="M22.5 6.908V6.75a3 3 0 00-3-3h-15a3 3 0 00-3 3v.158l9.714 5.978a1.5 1.5 0 001.572 0L22.5 6.908z"/></svg>
                            <span>Email</span>
                        </a>
                        <a href="https://www.linkedin.com/in/ali-cheraghian/" target="_blank" rel="noopener noreferrer" aria-label="View LinkedIn profile (opens in new tab)" class="social-link">
                            <svg class="social-icon" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                            <span>LinkedIn</span>
                        </a>
                        <a href="https://github.com/alichr" target="_blank" rel="noopener noreferrer" aria-label="View GitHub profile (opens in new tab)" class="social-link">
                            <svg class="social-icon" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
                            <span>GitHub</span>
                        </a>
                        <a href="https://scholar.google.com/citations?user=QT0EXIkAAAAJ" target="_blank" rel="noopener noreferrer" aria-label="View Google Scholar profile (opens in new tab)" class="social-link">
                            <svg class="social-icon" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M12 3L1 9l4 2.18v6L12 21l7-3.82v-6l2-1.09V17h2V9L12 3zm6.82 6L12 12.72 5.18 9 12 5.28 18.82 9zM17 15.99l-5 2.73-5-2.73v-3.72L12 15l5-2.73v3.72z"/></svg>
                            <span>Scholar</span>
                        </a>
                    </nav>
                </div>
            </div>
        </div>
    </header>

    <nav class="section-nav" role="navigation" aria-label="Page sections">
        <a href="#research-heading">Research</a>
        <a href="#news-heading">News</a>
        <a href="#education-heading">Education</a>
        <a href="#experience-heading">Experience</a>
        <a href="#publications-heading">Publications</a>
        <a href="#chatbot-heading">Ask Me</a>
    </nav>

    <main id="main-content" role="main">
        <section class="cv-section reveal" aria-labelledby="research-heading">
            <div class="cv-grid">
                <div class="cv-col">
                    <h2 id="research-heading">Research Areas</h2>
                    <div class="cv-list">
                        <div class="cv-item">
                            <span class="cv-title">Vision-Language Models</span>
                            <div class="cv-sub">CLIP adaptation, prompt-guided generation, VLM test-time adaptation</div>
                            <div class="research-venues">5 papers &middot; AAAI, BMVC, CVIU, DICTA</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-title">Knowledge Distillation</span>
                            <div class="cv-sub">Dynamic trade-off optimization, logit calibration, subspace methods</div>
                            <div class="research-venues">4 papers &middot; ICLR, WACV, TMLR, DICTA</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-title">3D Point Clouds</span>
                            <div class="cv-sub">Zero-shot recognition, capsule networks, pruning, classification</div>
                            <div class="research-venues">10 papers &middot; IJCV, ECCV, WACV, BMVC, MVA</div>
                        </div>
                    </div>
                </div>
                <div class="cv-col">
                    <h2 class="research-col-heading">&nbsp;</h2>
                    <div class="cv-list">
                        <div class="cv-item">
                            <span class="cv-title">Few-Shot &amp; Incremental Learning</span>
                            <div class="cv-sub">Semantic-aware distillation, synthesized features, 3D class-incremental</div>
                            <div class="research-venues">6 papers &middot; CVPR, ICCV, ECCV, ACCV</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-title">Test-Time Adaptation</span>
                            <div class="cv-sub">Continual domain adaptation, backprop-free methods, denoising diffusion</div>
                            <div class="research-venues">5 papers &middot; CVPR, AAAI, WACV, BMVC</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-title">Applied AI</span>
                            <div class="cv-sub">Satellite atmospheric correction, glaucoma diagnosis, IC design</div>
                            <div class="research-venues">3 papers &middot; US Patent, DICTA</div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="news-section reveal" aria-labelledby="news-heading">
            <h2 id="news-heading">News</h2>
            <ul>
                <li>Our US patent "Atmospheric Correction" (US App. 19/266,579) has been published â€” <span class="venue">US Patent 2026</span></li>
                <li>Our paper "DTO-KD: Dynamic Trade-off Optimization for Effective Knowledge Distillation" has been accepted as an <strong>Oral</strong> presentation at <span class="venue">ICLR'26</span></li>
                <li>Our paper "Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models" has been accepted to <span class="venue">AAAI'26</span></li>
                <li>Our paper "SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces" has been accepted to <span class="venue">WACV'26</span></li>
                <li>I have started a new position as Senior AI/ML Scientist at Macquarie University's Silicon Platforms Lab starting from <span class="venue">August 2025</span></li>
            </ul>
            <div class="news-older" id="news-older">
                <ul>
                    <li>Our paper "LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration" has been accepted to <span class="venue">TMLR'25</span></li>
                    <li>Our papers "ETTA: Efficient Test-Time Adaptation for Vision-Language Models" and "Task Progressive Curriculum Learning" have been accepted to <span class="venue">BMVC'25</span></li>
                    <li>Our paper "Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models" has been accepted to <span class="venue">WACV'25</span></li>
                    <li>Our paper "Canonical shape projection is all you need for 3d few-shot class incremental learning" has been accepted to <span class="venue">ECCV'24</span></li>
                    <li>Our paper "Backpropagation-free Network for 3D Test-time Adaptation" has been accepted to <span class="venue">CVPR'24</span></li>
                    <li>Our paper "Continual test-time domain adaptation via dynamic sample selection" has been accepted to <span class="venue">WACV'24</span></li>
                    <li>Our paper "Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor" has been accepted to <span class="venue">ACCV'24</span></li>
                    <li>Our paper "3D Point Cloud Network Pruning: When Some Weights Do not Matter" has been accepted to <span class="venue">BMVC'24</span></li>
                    <li>Our paper "3D scene generation for zero-shot learning using ChatGPT guided language prompts" has been accepted to <span class="venue">CVIU'24</span></li>
                    <li>Our papers "Efficient Atmospheric Correction" and "Enhancing Glaucoma Diagnosis" have been accepted to <span class="venue">DICTA'24</span></li>
                </ul>
            </div>
            <button class="news-toggle" id="news-toggle" type="button" aria-expanded="false" aria-controls="news-older">Show older news</button>
        </section>

        <section class="cv-section reveal" aria-labelledby="education-heading">
            <div class="cv-grid">
                <div class="cv-col">
                    <h2 id="education-heading">Education</h2>
                    <div class="cv-list">
                        <div class="cv-item">
                            <span class="cv-year">2016 â€” 2022</span>
                            <span class="cv-title">Ph.D., Engineering and Computer Science</span>, Australian National University (ANU)
                            <div class="cv-sub">Thesis: <em>Exploring 3D Data and Beyond in a Low Data Regime</em><br>Supervisors: Dr. Lars Petersson, Dr. Dylan Campbell, Dr. Mehrtash Harandi</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-year">2009 â€” 2011</span>
                            <span class="cv-title">M.Sc., Computer Science</span>, Amirkabir University of Technology
                            <div class="cv-sub">Thesis: <em>3D Face Recognition Robust to Pose Variation</em><br>Supervisor: Dr. Karim Faez</div>
                        </div>
                        <div class="cv-item">
                            <span class="cv-year">2004 â€” 2008</span>
                            <span class="cv-title">B.Sc., Electrical Engineering</span>, Shiraz University of Technology
                            <div class="cv-sub">Thesis: <em>Microcontroller-Based Electronic Calendar System</em><br>Supervisor: Dr. Mohammad Sadegh Hadaegh</div>
                        </div>
                    </div>
                </div>
                <div class="cv-col">
                    <h2 id="experience-heading">Experience</h2>
                    <div class="cv-list">
                        <div class="cv-item">
                            <span class="cv-year">2025 â€” Present</span>
                            <span class="cv-title">Senior AI/ML Scientist</span>, Macquarie University
                        </div>
                        <div class="cv-item">
                            <span class="cv-year">2024 â€” Present</span>
                            <span class="cv-title">Adjunct Lecturer</span>, Australian National University (ANU)
                        </div>
                        <div class="cv-item">
                            <span class="cv-year">2024 â€” Present</span>
                            <span class="cv-title">Adjunct Senior ML Scientist</span>, University of Technology Sydney (UTS)
                        </div>
                        <div class="cv-item">
                            <span class="cv-year">2020 â€” 2025</span>
                            <span class="cv-title">Computer Vision Scientist</span>, CSIRO Data61
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="publications-section reveal" aria-labelledby="publications-heading">
            <h2 id="publications-heading">Publications</h2>
            <div class="stats-container">
                <div class="citation-graph" aria-label="Citations over time chart">
                    <h3>Citations Over Time</h3>
                    <canvas id="citationChart" aria-label="Bar chart showing citation counts from 2017 to 2026"></canvas>
                </div>
                <div class="citation-stats" aria-labelledby="citation-metrics-heading">
                    <h3 id="citation-metrics-heading">Citation Metrics</h3>
                    <div class="stat-item">
                        <span class="stat-label">Total Citations</span>
                        <span class="stat-value">930</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">h-index</span>
                        <span class="stat-value">12</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">i10-index</span>
                        <span class="stat-value">13</span>
                    </div>
                </div>
            </div>

            <div class="publications-list">
                <h3 class="sr-only">Publication List by Year</h3>

                <div class="pub-filters" role="group" aria-label="Filter publications by topic">
                    <button class="filter-btn active" data-filter="all" type="button">All</button>
                    <button class="filter-btn" data-filter="vlm" type="button">VLMs</button>
                    <button class="filter-btn" data-filter="distillation" type="button">Distillation</button>
                    <button class="filter-btn" data-filter="3d" type="button">3D Points</button>
                    <button class="filter-btn" data-filter="few-shot" type="button">Few-Shot</button>
                    <button class="filter-btn" data-filter="tta" type="button">Test-Time</button>
                </div>

                <h4>2026</h4>
                <ul>
                    <li data-topic="vlm tta 3d">
                        <img src="./images/papers/Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models</strong></a><br>
                            Mehran Tamjidi, Hamidreza Dastmalchi, Mohammadreza Alimoradijazi, Ali Cheraghian, Aijun An, Morteza Saberi<br>
                            AAAI 2026 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="distillation">
                        <img src="./images/papers/SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces</strong></a><br>
                            Zeeshan Hayder, Ali Cheraghian, Lars Petersson, Mehrtash Harandi<br>
                            WACV 2026 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="distillation">
                        <img src="./images/papers/DTO-KD_Dynamic_Trade-off_Optimization_for_Effective_Knowledge_Distillation.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>DTO-KD: Dynamic Trade-off Optimization for Effective Knowledge Distillation</strong></a><br>
                            Zeeshan Hayder, Ali Cheraghian, Lars Petersson, Mehrtash Harandi, Richard Hartley<br>
                            ICLR 2026 <span class="publication-badge">Oral</span> <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                </ul>

                <h4>2025</h4>
                <ul>
                    <li data-topic="distillation">
                        <img src="./images/papers/LumiNet: Perception-Driven Knowledge Distillation.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration</strong></a><br>
                            MI Hossain, MM Lutfe Elahi, S Ramasinghe, A Cheraghian, F Rahman, N Mohammed, S Rahman<br>
                            TMLR 2025 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="vlm tta">
                        <img src="./images/papers/ETTA_Efficient Test-Time Adaptation for Vision-Language Models.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates</strong></a><br>
                            H Dastmalchi, A An, A Cheraghian<br>
                            BMVC 2025 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="vlm">
                        <img src="./images/papers/Task Progressive Curriculum Learning.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="#" target="_blank" rel="noopener noreferrer"><strong>Task Progressive Curriculum Learning for Robust Visual Question Answering</strong></a><br>
                            A Akl, A Khamis, Z Wang, A Cheraghian, S Khalifa, K Wang<br>
                            BMVC 2025 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="tta 3d">
                        <img src="./images/papers/Test_Time_Adaptation_3D_Point_Clouds.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/2411.14495" target="_blank" rel="noopener noreferrer"><strong>Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models</strong></a><br>
                            H Dastmalchi, A An, A Cheraghian, S Rahman, S Ramasinghe<br>
                            WACV 2025 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                </ul>

                <h4>2024</h4>
                <ul>
                    <li data-topic="tta 3d">
                        <img src="./images/papers/Backpropagation-free_Network_for_3D_Test-time_Adaptation.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Backpropagation-free_Network_for_3D_Test-time_Adaptation_CVPR_2024_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Backpropagation-free Network for 3D Test-time Adaptation</strong></a><br>
                            Y Wang, A Cheraghian, Z Hayder, J Hong, S Ramasinghe, S Rahman<br>
                            CVPR 2024 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="tta">
                        <img src="./images/papers/Continual_test-time_domain_adaptation_via_dynamic_sample_selection.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Continual test-time domain adaptation via dynamic sample selection</strong></a><br>
                            Y Wang, J Hong, A Cheraghian, S Rahman, D Ahmedt-Aristizabal<br>
                            WACV 2024 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="few-shot 3d">
                        <img src="./images/papers/Canonical_shape_projection_is_all_you_need_for_3d_few-shot_class_incremental_learning.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05717.pdf" target="_blank" rel="noopener noreferrer"><strong>Canonical shape projection is all you need for 3d few-shot class incremental learning</strong></a><br>
                            A Cheraghian, Z Hayder, S Ramasinghe, S Rahman, J Jafaryahya<br>
                            ECCV 2024 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="few-shot 3d">
                        <img src="./images/papers/Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Ahmadi_Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor_ACCV_2024_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor</strong></a><br>
                            S Ahmadi, A Cheraghian, M Saberi, MT Abir, H Dastmalchi, F Hussain<br>
                            ACCV 2024
                        </article>
                    </li>
                    <li data-topic="3d">
                        <img src="./images/papers/3D_Point_Cloud_Network_Pruning_When_Some_Weights_Do_not_Matter.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_637/paper.pdf" target="_blank" rel="noopener noreferrer"><strong>3D Point Cloud Network Pruning: When Some Weights Do not Matter</strong></a><br>
                            A Biswas, MI Hossain, MM Elahi, A Cheraghian, F Rahman<br>
                            BMVC 2024 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="vlm 3d">
                        <img src="./images/papers/3D_scene_generation_for_zero-shot_learning_using_ChatGPT_guided_language_prompts.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/pii/S1077314224002923" target="_blank" rel="noopener noreferrer"><strong>3D scene generation for zero-shot learning using ChatGPT guided language prompts</strong></a><br>
                            S Ahmadi, A Cheraghian, TF Chowdhury, M Saberi, S Rahman<br>
                            CVIU 2024 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="distillation">
                        <img src="./images/papers/Efficient_Atmospheric_Correction.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869604" target="_blank" rel="noopener noreferrer"><strong>Efficient Atmospheric Correction for Onboard Processing Using Knowledge Distillation and Model Compression</strong></a><br>
                            M Zhang, A Cheraghian, Y Qin, D Benn, T Rollan, N Habili<br>
                            DICTA 2024
                        </article>
                    </li>
                    <li data-topic="vlm">
                        <img src="./images/papers/Enhancing_Glaucoma_Diagnosis.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869527" target="_blank" rel="noopener noreferrer"><strong>Enhancing Glaucoma Diagnosis through Vision-Language Models and Large Language Model Descriptions</strong></a><br>
                            HY Bae, M Saberi, S Shariflou, M Kalloniatis, J Phu, A Agar, A Cheraghian<br>
                            DICTA 2024
                        </article>
                    </li>
                </ul>

                <h4>2023</h4>
                <ul>
                    <li data-topic="vlm 3d">
                        <img src="./images/papers/ChatGPT-guided_Semantics_for_Zero-shot_Learning.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/2310.11657" target="_blank" rel="noopener noreferrer"><strong>ChatGPT-guided Semantics for Zero-shot Learning</strong></a><br>
                            FH Shubho, TF Chowdhury, A Cheraghian, M Saberi, N Mohammed<br>
                            DICTA 2023
                        </article>
                    </li>
                </ul>

                <h4>2022</h4>
                <ul>
                    <li data-topic="3d">
                        <img src="./images/papers/Zero-shot_learning_on_3d_point_cloud_objects_and_beyond.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/2104.04980" target="_blank" rel="noopener noreferrer"><strong>Zero-shot learning on 3d point cloud objects and beyond</strong></a><br>
                            A Cheraghian, S Rahman, TF Chowdhury, D Campbell, L Petersson<br>
                            IJCV 2022 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="few-shot 3d">
                        <img src="./images/papers/Few-shot_class-incremental_learning_for_3d_point_cloud_objects.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800194.pdf" target="_blank" rel="noopener noreferrer"><strong>Few-shot class-incremental learning for 3d point cloud objects</strong></a><br>
                            T Chowdhury, A Cheraghian, S Ramasinghe, S Ahmadi, M Saberi<br>
                            ECCV 2022 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="vlm 3d">
                        <img src="./images/papers/Prompt-guided_scene_generation_for_3d_zero-shot_learning.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/2209.14690" target="_blank" rel="noopener noreferrer"><strong>Prompt-guided scene generation for 3d zero-shot learning</strong></a><br>
                            M Nasiri, A Cheraghian, TF Chowdhury, S Ahmadi, M Saberi, S Rahman<br>
                            DICTA 2022
                        </article>
                    </li>
                </ul>

                <h4>2021</h4>
                <ul>
                    <li data-topic="distillation few-shot">
                        <img src="./images/papers/Semantic-aware_knowledge_distillation_for_few-shot_class-incremental_learning.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Semantic-aware knowledge distillation for few-shot class-incremental learning</strong></a><br>
                            A Cheraghian, S Rahman, P Fang, SK Roy, L Petersson, M Harandi<br>
                            CVPR 2021 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="few-shot">
                        <img src="./images/papers/Synthesized_feature_based_few-shot_class-incremental_learning_on_a_mixture_of_subspaces.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cheraghian_Synthesized_Feature_Based_Few-Shot_Class-Incremental_Learning_on_a_Mixture_of_ICCV_2021_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Synthesized feature based few-shot class-incremental learning on a mixture of subspaces</strong></a><br>
                            A Cheraghian, S Rahman, S Ramasinghe, P Fang, C Simon, L Petersson<br>
                            ICCV 2021 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                    <li data-topic="few-shot 3d">
                        <img src="./images/papers/Learning_without_forgetting_for_3d_point_cloud_objects.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/2106.14275" target="_blank" rel="noopener noreferrer"><strong>Learning without forgetting for 3d point cloud objects</strong></a><br>
                            T Chowdhury, M Jalisha, A Cheraghian, S Rahman<br>
                            IWANN 2021
                        </article>
                    </li>
                </ul>

                <h4>2020</h4>
                <ul>
                    <li data-topic="3d">
                        <img src="./images/papers/Transductive_zero-shot_learning_for_3d_point_cloud_classification.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Cheraghian_Transductive_Zero-Shot_Learning_for_3D_Point_Cloud_Classification_WACV_2020_paper.pdf" target="_blank" rel="noopener noreferrer"><strong>Transductive zero-shot learning for 3d point cloud classification</strong></a><br>
                            A Cheraghian, S Rahman, D Campbell, L Petersson<br>
                            WACV 2020 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                </ul>

                <h4>Earlier Publications</h4>
                <ul>
                    <li data-topic="3d">
                        <img src="./images/papers/Zero-shot_learning_of_3d_point_cloud_objects.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/1902.10272" target="_blank" rel="noopener noreferrer"><strong>Zero-shot learning of 3d point cloud objects</strong></a><br>
                            A Cheraghian, S Rahman, L Petersson<br>
                            MVA 2019
                        </article>
                    </li>
                    <li data-topic="3d">
                        <img src="./images/papers/3dcapsule_Extending_the_capsule_architecture_to_classify_3d_point_clouds.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://arxiv.org/pdf/1811.02191" target="_blank" rel="noopener noreferrer"><strong>3dcapsule: Extending the capsule architecture to classify 3d point clouds</strong></a><br>
                            A Cheraghian, L Petersson<br>
                            WACV 2019 <span class="venue-badge tier-2">Rank A</span>
                        </article>
                    </li>
                    <li data-topic="3d">
                        <img src="./images/papers/Surface_geodesic_pattern_for_3D_deformable_texture_matching.webp" alt="" class="publication-thumbnail" loading="lazy" width="130" height="90">
                        <article class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320316302321" target="_blank" rel="noopener noreferrer"><strong>Surface geodesic pattern for 3D deformable texture matching</strong></a><br>
                            F Hajati, A Cheraghian, S Gheisari, Y Gao, AS Mian<br>
                            Pattern Recognition 2017 <span class="venue-badge tier-1">Rank A*</span>
                        </article>
                    </li>
                </ul>
            </div>
        </section>

        <section class="chatbot-section reveal" aria-labelledby="chatbot-heading">
            <h2 id="chatbot-heading">Ask Me Anything</h2>
            <p class="chatbot-intro">Have questions about my research or publications? Chat with my AI assistant.</p>
            <div class="chatbot-actions">
                <div class="sample-questions" role="list" aria-label="Sample questions you can ask">
                    <span class="sample-question" role="listitem" tabindex="0">Research areas</span>
                    <span class="sample-question" role="listitem" tabindex="0">Publications</span>
                    <span class="sample-question" role="listitem" tabindex="0">Career journey</span>
                    <span class="sample-question" role="listitem" tabindex="0">Collaborate</span>
                </div>
                <a href="https://huggingface.co/spaces/alichr/career_conversation" target="_blank" rel="noopener noreferrer" class="chatbot-launch-button" aria-label="Start conversation with AI assistant (opens in new tab)">
                    Start Conversation &rarr;
                </a>
            </div>
        </section>
    </main>

    <footer role="contentinfo">
        <div class="footer-content">
            <p class="footer-copyright">&copy; <span id="current-year">2026</span> Ali Cheraghian. All rights reserved.</p>
            <div class="visitor-counter" aria-label="Visitor counter">
                <span class="visitor-counter-label">Visitors:</span>
                <a href="https://info.flagcounter.com/8m5j" target="_blank" rel="noopener noreferrer" aria-label="View visitor statistics">
                    <img src="https://s11.flagcounter.com/mini/8m5j/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" alt="Visitor Counter">
                </a>
            </div>
        </div>
    </footer>

    <script>
        // Dark mode toggle functionality
        (function() {
            const themeToggle = document.getElementById('theme-toggle');
            const themeColorMeta = document.getElementById('theme-color-meta');

            function updateThemeColor() {
                const isDark = document.documentElement.classList.contains('dark-mode');
                themeColorMeta.setAttribute('content', isDark ? '#0d1117' : '#002b5e');
            }

            themeToggle.addEventListener('click', function() {
                document.documentElement.classList.toggle('dark-mode');
                const isDark = document.documentElement.classList.contains('dark-mode');
                localStorage.setItem('theme', isDark ? 'dark' : 'light');
                updateThemeColor();

                // Update chart colors
                if (typeof citationChart !== 'undefined') {
                    const gridColor = isDark ? 'rgba(255, 255, 255, 0.1)' : 'rgba(0, 0, 0, 0.05)';
                    const tickColor = isDark ? '#c9d1d9' : '#333';
                    citationChart.options.scales.y.grid.color = gridColor;
                    citationChart.options.scales.y.ticks.color = tickColor;
                    citationChart.options.scales.x.ticks.color = tickColor;
                    citationChart.update();
                }
            });

            // Update theme color on load
            updateThemeColor();

            // Listen for system preference changes
            window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', function(e) {
                if (!localStorage.getItem('theme')) {
                    if (e.matches) {
                        document.documentElement.classList.add('dark-mode');
                    } else {
                        document.documentElement.classList.remove('dark-mode');
                    }
                    updateThemeColor();
                }
            });
        })();

        // Update copyright year
        document.getElementById('current-year').textContent = new Date().getFullYear();

        // Citation chart (wrapped in DOMContentLoaded since Chart.js is deferred)
        var citationChart;
        document.addEventListener('DOMContentLoaded', function() {
            const ctx = document.getElementById('citationChart').getContext('2d');
            const isDark = document.documentElement.classList.contains('dark-mode');

            // Generate gradient blue colors for bars (lighter to darker)
            var barCount = 10;
            var bgColors = [];
            var borderColors = [];
            var hoverColors = [];
            for (var i = 0; i < barCount; i++) {
                var t = i / (barCount - 1);
                var r = Math.round(180 - t * 150);
                var g = Math.round(210 - t * 80);
                var b = Math.round(255 - t * 30);
                bgColors.push('rgba(' + r + ',' + g + ',' + b + ',0.7)');
                borderColors.push('rgba(' + r + ',' + g + ',' + b + ',1)');
                hoverColors.push('rgba(' + r + ',' + g + ',' + b + ',0.9)');
            }

            citationChart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: ['2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026'],
                    datasets: [{
                        label: 'Citations',
                        data: [3, 5, 8, 25, 44, 113, 207, 228, 271, 15], // citation data per year
                        backgroundColor: bgColors,
                        borderColor: borderColors,
                        borderWidth: 1,
                        borderRadius: 5,
                        hoverBackgroundColor: hoverColors
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: {
                            display: false
                        }
                    },
                    scales: {
                        y: {
                            beginAtZero: true,
                            grid: {
                                color: isDark ? 'rgba(255, 255, 255, 0.1)' : 'rgba(0, 0, 0, 0.05)'
                            },
                            ticks: {
                                font: {
                                    family: 'Montserrat'
                                },
                                color: isDark ? '#c9d1d9' : '#333'
                            }
                        },
                        x: {
                            grid: {
                                display: false
                            },
                            ticks: {
                                font: {
                                    family: 'Montserrat'
                                },
                                color: isDark ? '#c9d1d9' : '#333'
                            }
                        }
                    },
                    animation: {
                        duration: 2000,
                        easing: 'easeInOutQuart'
                    },
                    hover: {
                        mode: 'nearest',
                        intersect: true
                    }
                }
            });
        });

        // News toggle
        (function() {
            const toggle = document.getElementById('news-toggle');
            const older = document.getElementById('news-older');
            if (toggle && older) {
                toggle.addEventListener('click', function() {
                    const isExpanded = older.classList.toggle('expanded');
                    toggle.setAttribute('aria-expanded', isExpanded);
                    toggle.textContent = isExpanded ? 'Show less' : 'Show older news';
                });
            }
        })();

        // Scroll reveal animations
        (function() {
            var reveals = document.querySelectorAll('.reveal');
            if ('IntersectionObserver' in window) {
                var observer = new IntersectionObserver(function(entries) {
                    entries.forEach(function(entry) {
                        if (entry.isIntersecting) {
                            entry.target.classList.add('visible');
                            observer.unobserve(entry.target);
                        }
                    });
                }, { threshold: 0.1 });
                reveals.forEach(function(el) { observer.observe(el); });
            } else {
                reveals.forEach(function(el) { el.classList.add('visible'); });
            }
        })();

        // Interactive sample questions for chatbot
        document.addEventListener('DOMContentLoaded', function() {
            const sampleQuestions = document.querySelectorAll('.sample-question');
            const chatbotButton = document.querySelector('.chatbot-launch-button');

            sampleQuestions.forEach(question => {
                // Click handler
                question.addEventListener('click', function() {
                    this.style.transform = 'scale(0.95)';
                    this.style.background = 'rgba(255, 255, 255, 0.4)';

                    setTimeout(() => {
                        this.style.transform = '';
                        this.style.background = '';
                    }, 150);

                    setTimeout(() => {
                        window.open(chatbotButton.href, '_blank');
                    }, 200);
                });

                // Keyboard handler for accessibility
                question.addEventListener('keydown', function(e) {
                    if (e.key === 'Enter' || e.key === ' ') {
                        e.preventDefault();
                        this.click();
                    }
                });
            });
        });

        // Scroll-spy: highlight active section in nav
        (function() {
            var sections = document.querySelectorAll('main section[aria-labelledby]');
            var navLinks = document.querySelectorAll('.section-nav a');

            if ('IntersectionObserver' in window) {
                var observer = new IntersectionObserver(function(entries) {
                    entries.forEach(function(entry) {
                        if (entry.isIntersecting) {
                            var id = entry.target.querySelector('h2').id;
                            navLinks.forEach(function(link) {
                                link.classList.toggle('active', link.getAttribute('href') === '#' + id);
                            });
                        }
                    });
                }, { rootMargin: '-20% 0px -80% 0px' });

                sections.forEach(function(section) { observer.observe(section); });
            }
        })();

        // Publication topic filters
        (function() {
            var filterBtns = document.querySelectorAll('.filter-btn');
            var pubItems = document.querySelectorAll('.publications-list li[data-topic]');
            var yearHeadings = document.querySelectorAll('.publications-list h4');

            filterBtns.forEach(function(btn) {
                btn.addEventListener('click', function() {
                    var filter = this.getAttribute('data-filter');

                    // Update active button
                    filterBtns.forEach(function(b) { b.classList.remove('active'); });
                    this.classList.add('active');

                    // Filter publications
                    pubItems.forEach(function(item) {
                        if (filter === 'all' || item.getAttribute('data-topic').indexOf(filter) !== -1) {
                            item.style.display = '';
                        } else {
                            item.style.display = 'none';
                        }
                    });

                    // Hide year headings with no visible papers
                    yearHeadings.forEach(function(heading) {
                        var ul = heading.nextElementSibling;
                        if (ul && ul.tagName === 'UL') {
                            var visibleItems = ul.querySelectorAll('li:not([style*="display: none"])');
                            heading.style.display = visibleItems.length === 0 ? 'none' : '';
                            ul.style.display = visibleItems.length === 0 ? 'none' : '';
                        }
                    });
                });
            });
        })();
    </script>
</body>

</html>
