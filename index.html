<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Ali Cheraghian - Research Scientist specializing in AI, Machine Learning, and Computer Vision">
    <title>Ali Cheraghian - Research Scientist</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --primary-color: #002b5e;
            --secondary-color: #a7c5ed;
            --text-color: #333;
            --bg-color: #f0f4f8;
            --card-bg: #fff;
            --hover-color: #003875;
            --animation-duration: 0.5s;
            --animation-timing: cubic-bezier(0.4, 0, 0.2, 1);
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }
            to {
                opacity: 1;
            }
        }

        @keyframes scaleIn {
            from {
                transform: scale(0.95);
                opacity: 0;
            }
            to {
                transform: scale(1);
                opacity: 1;
            }
        }

        @keyframes slideInLeft {
            from {
                transform: translateX(-20px);
                opacity: 0;
            }
            to {
                transform: translateX(0);
                opacity: 1;
            }
        }

        @keyframes slideInRight {
            from {
                transform: translateX(20px);
                opacity: 0;
            }
            to {
                transform: translateX(0);
                opacity: 1;
            }
        }

        body {
            font-family: 'Montserrat', sans-serif;
            margin: 0;
            padding: 0;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }

        header {
            background: var(--primary-color);
            color: #fff;
            padding: 3rem 0;
            position: relative;
            overflow: hidden;
        }

        header::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: var(--secondary-color);
        }

        .header-content {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            text-align: center;
        }

        header h1 {
            font-size: 3rem;
            margin: 0;
            letter-spacing: 1px;
            animation: fadeInUp var(--animation-duration) var(--animation-timing);
        }

        header .title {
            font-size: 1.4rem;
            margin: 1rem 0;
            color: var(--secondary-color);
            animation: fadeInUp var(--animation-duration) var(--animation-timing) 0.2s;
        }

        .contact-links {
            margin: 1.5rem 0;
            animation: fadeInUp var(--animation-duration) var(--animation-timing) 0.4s;
        }

        .contact-links a {
            color: var(--secondary-color);
            text-decoration: none;
            margin: 0 1rem;
            padding: 0.5rem 1rem;
            border: 1px solid var(--secondary-color);
            border-radius: 4px;
            transition: all 0.3s ease;
        }

        .contact-links a:hover {
            background: var(--secondary-color);
            color: var(--primary-color);
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .profile-photo {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            margin: 0 auto 2rem;
            display: block;
            border: 4px solid var(--secondary-color);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            object-fit: cover;
            animation: scaleIn var(--animation-duration) var(--animation-timing);
        }

        @media (max-width: 768px) {
            .profile-photo {
                width: 150px;
                height: 150px;
            }
        }

        .contact-info {
            max-width: 800px;
            margin: 2rem auto;
            text-align: center;
            color: var(--secondary-color);
            font-size: 1.1rem;
            line-height: 1.8;
        }

        .contact-info p {
            margin: 0.5rem 0;
        }

        .news-section {
            max-width: 800px;
            margin: 3rem auto;
            text-align: left;
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            animation: fadeInUp var(--animation-duration) var(--animation-timing) 0.6s;
        }

        .news-section h2 {
            text-align: left;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
            font-size: 1.5rem;
            position: relative;
            padding-bottom: 0.5rem;
        }

        .news-section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 40px;
            height: 2px;
            background: var(--secondary-color);
        }

        .news-section ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }

        .news-section li {
            position: relative;
            padding: 0.8rem 0;
            margin-bottom: 0.5rem;
            color: var(--text-color);
            font-size: 0.95rem;
            line-height: 1.6;
            border-bottom: 1px solid rgba(0, 43, 94, 0.1);
            transition: transform 0.3s ease;
        }

        .news-section li:last-child {
            border-bottom: none;
        }

        .news-section li:before {
            content: "â€¢";
            position: absolute;
            left: -1rem;
            color: var(--primary-color);
        }

        .news-section li:hover {
            transform: translateX(5px);
        }

        .news-section a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s ease;
        }

        .news-section a:hover {
            color: var(--hover-color);
        }

        main {
            padding: 2rem;
            max-width: 1200px;
            margin: 0 auto;
        }

        .stats-container {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 2rem;
            margin-top: 2rem;
        }

        .citation-graph {
            flex: 1;
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            height: 300px;
            animation: slideInLeft var(--animation-duration) var(--animation-timing) 0.8s;
        }

        .citation-graph h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .citation-stats {
            flex: 1;
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            animation: slideInRight var(--animation-duration) var(--animation-timing) 0.8s;
        }

        .citation-stats h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .stat-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.8rem;
            padding-bottom: 0.8rem;
            border-bottom: 1px solid rgba(0, 43, 94, 0.1);
            transition: transform 0.3s ease;
        }

        .stat-item:last-child {
            border-bottom: none;
        }

        .stat-item:hover {
            transform: translateX(5px);
        }

        .stat-label {
            color: var(--text-color);
            font-size: 0.95rem;
        }

        .stat-value {
            color: var(--primary-color);
            font-weight: 600;
        }

        .publications-section {
            max-width: 1200px;
            margin: 3rem auto;
            text-align: left;
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            animation: fadeInUp var(--animation-duration) var(--animation-timing) 1s;
        }

        .publications-section h2 {
            text-align: left;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
            font-size: 1.5rem;
            position: relative;
            padding-bottom: 0.5rem;
        }

        .publications-section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 40px;
            height: 2px;
            background: var(--secondary-color);
        }

        .publications-list {
            margin-top: 2rem;
        }

        .publications-list h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .publications-list h4 {
            color: var(--primary-color);
            font-size: 1.3rem;
            margin: 2rem 0 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--secondary-color);
        }

        .publications-list h4:first-child {
            margin-top: 0;
        }

        .publications-list ul {
            margin-bottom: 1rem;
        }

        .publications-list ul:last-child {
            margin-bottom: 0;
        }

        .publications-list li {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
            align-items: flex-start;
            transition: transform 0.3s ease;
        }

        .publications-list li:hover {
            transform: translateX(5px);
        }

        .publication-thumbnail {
            width: 120px;
            height: 80px;
            object-fit: contain;
            background-color: transparent;
            padding: 0;
            margin: 0;
            display: block;
            transition: transform 0.3s ease;
        }

        .publications-list li:hover .publication-thumbnail {
            transform: scale(1.05);
        }

        .publication-content {
            flex: 1;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
        }

        .publication-content strong {
            color: var(--primary-color);
            font-size: 1.1rem;
            margin-bottom: 0.3rem;
            line-height: 1.3;
        }

        .publication-content a {
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .publication-content a:hover {
            color: var(--hover-color);
        }

        .publication-content br + text {
            font-size: 0.9rem;
            color: var(--text-color);
            opacity: 0.9;
        }

        .venue {
            color: var(--primary-color);
            font-weight: 600;
        }

        .chatbot-section {
            max-width: 900px;
            margin: 3rem auto;
            text-align: left;
            background: var(--card-bg);
            padding: 2.5rem;
            border-radius: 16px;
            box-shadow: 0 8px 32px rgba(0, 43, 94, 0.1);
            animation: fadeInUp var(--animation-duration) var(--animation-timing) 0.8s;
            border: 1px solid rgba(167, 197, 237, 0.2);
            position: relative;
            overflow: hidden;
        }

        .chatbot-section::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, var(--primary-color), var(--secondary-color), #00d4ff);
            animation: shimmer 3s ease-in-out infinite;
        }

        @keyframes shimmer {
            0%, 100% { opacity: 0.7; }
            50% { opacity: 1; }
        }

        .chatbot-section h2 {
            text-align: left;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
            font-size: 1.5rem;
            position: relative;
            padding-bottom: 0.5rem;
        }

        .chatbot-section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 40px;
            height: 2px;
            background: var(--secondary-color);
        }

        .chatbot-description {
            margin-bottom: 2rem;
            color: var(--text-color);
            line-height: 1.6;
        }

        .chatbot-container {
            position: relative;
            width: 100%;
            min-height: 450px;
            border-radius: 20px;
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 50%, #00d4ff 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 12px 40px rgba(0, 43, 94, 0.2);
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            overflow: hidden;
        }

        .chatbot-container::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            animation: rotate 20s linear infinite;
            pointer-events: none;
        }

        @keyframes rotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .chatbot-container:hover {
            transform: translateY(-6px) scale(1.02);
            box-shadow: 0 20px 60px rgba(0, 43, 94, 0.3);
        }

        .chatbot-placeholder {
            text-align: center;
            color: white;
            padding: 3rem 2rem;
            max-width: 600px;
            position: relative;
            z-index: 2;
        }

        .chatbot-icon {
            font-size: 5rem;
            margin-bottom: 2rem;
            animation: float 3s ease-in-out infinite;
            filter: drop-shadow(0 4px 8px rgba(0, 0, 0, 0.3));
        }

        @keyframes float {
            0%, 100% {
                transform: translateY(0px) rotate(0deg);
            }
            33% {
                transform: translateY(-10px) rotate(2deg);
            }
            66% {
                transform: translateY(5px) rotate(-1deg);
            }
        }

        .chatbot-placeholder h3 {
            font-size: 2.2rem;
            margin-bottom: 1.5rem;
            font-weight: 700;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
            animation: fadeInUp 0.8s ease-out 0.3s both;
        }

        .chatbot-placeholder p {
            font-size: 1.2rem;
            margin-bottom: 2.5rem;
            opacity: 0.95;
            line-height: 1.7;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.2);
            animation: fadeInUp 0.8s ease-out 0.6s both;
        }

        .sample-questions {
            margin: 2rem 0;
            display: flex;
            flex-wrap: wrap;
            gap: 0.8rem;
            justify-content: center;
            animation: fadeInUp 0.8s ease-out 0.9s both;
        }

        .sample-question {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            padding: 0.6rem 1.2rem;
            border-radius: 25px;
            font-size: 0.9rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            transition: all 0.3s ease;
            cursor: pointer;
            backdrop-filter: blur(10px);
        }

        .sample-question:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }

        .chatbot-launch-button {
            display: inline-block;
            padding: 1.2rem 3rem;
            background: linear-gradient(45deg, #ffffff, #f8f9ff);
            color: var(--primary-color);
            text-decoration: none;
            border-radius: 50px;
            font-weight: 700;
            font-size: 1.2rem;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.2);
            border: 3px solid rgba(255, 255, 255, 0.8);
            position: relative;
            overflow: hidden;
            animation: fadeInUp 0.8s ease-out 1.2s both;
        }

        .chatbot-launch-button::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);
            transition: left 0.6s ease;
        }

        .chatbot-launch-button:hover::before {
            left: 100%;
        }

        .chatbot-launch-button:hover {
            background: linear-gradient(45deg, var(--secondary-color), #00d4ff);
            color: white;
            transform: translateY(-3px) scale(1.05);
            box-shadow: 0 12px 35px rgba(0, 43, 94, 0.4);
            border-color: rgba(255, 255, 255, 0.9);
        }

        .ai-features {
            margin-top: 2rem;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1rem;
            animation: fadeInUp 0.8s ease-out 1.5s both;
        }

        .ai-feature {
            background: rgba(255, 255, 255, 0.1);
            padding: 1rem;
            border-radius: 12px;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }

        .ai-feature:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-3px);
        }

        .ai-feature-icon {
            font-size: 1.8rem;
            margin-bottom: 0.5rem;
            display: block;
        }

        .ai-feature-text {
            font-size: 0.85rem;
            font-weight: 500;
        }

        @media (max-width: 768px) {
            .chatbot-section {
                padding: 2rem;
                margin: 2rem auto;
            }
            
            .chatbot-container {
                min-height: 400px;
                border-radius: 16px;
            }
            
            .chatbot-placeholder {
                padding: 2.5rem 1.5rem;
            }
            
            .chatbot-icon {
                font-size: 4rem;
            }
            
            .chatbot-placeholder h3 {
                font-size: 1.8rem;
            }
            
            .chatbot-placeholder p {
                font-size: 1.1rem;
            }

            .sample-questions {
                gap: 0.6rem;
            }

            .sample-question {
                padding: 0.5rem 1rem;
                font-size: 0.85rem;
            }

            .chatbot-launch-button {
                padding: 1rem 2rem;
                font-size: 1.1rem;
            }

            .ai-features {
                grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
                gap: 0.8rem;
            }

            .ai-feature {
                padding: 0.8rem;
            }

            .ai-feature-icon {
                font-size: 1.5rem;
            }

            .ai-feature-text {
                font-size: 0.8rem;
            }
        }
    </style>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>

<body>
    <header>
        <div class="header-content">
            <img src="./images/profile.webp" alt="Ali Cheraghian" class="profile-photo" loading="lazy">
            <h1>Ali Cheraghian</h1>
            <div class="title">Senior AI/ML Scientist at Macquarie University | Former Computer Vision Scientist at CSIRO Data61 | Adjunct Faculty at ANU</div>
            <div class="contact-links">
                <a href="mailto:ali.cheraghian@mq.edu.au">Email</a>
                <a href="https://www.linkedin.com/in/ali-cheraghian/" target="_blank">LinkedIn</a>
                <a href="https://github.com/alichr" target="_blank">GitHub</a>
                <a href="https://scholar.google.com/citations?user=QT0EXIkAAAAJ" target="_blank">Google Scholar</a>
            </div>
            <p style="max-width: 800px; margin: 2rem auto; line-height: 1.8; text-align: justify;">
                I am a Senior AI/ML Scientist at Macquarie University, former Computer Vision Scientist at CSIRO Data61, and Adjunct Faculty Member at the Australian National University (ANU). My expertise spans large vision-language models (VLMs), large language models (LLMs), generative AI, knowledge distillation, and incremental learning.

                With extensive experience in both research and engineering, I design and deploy scalable AI/ML solutions that bridge cutting-edge methods with real-world applications. My current focus is on bringing advanced AI into integrated circuit (IC) design and silicon platforms, leveraging deep learning and LLMs to accelerate chip design workflows and enable next-generation semiconductor innovation.

                My work spans academia and industry, combining top-tier research (publications, patents, and IP development) with applied impact. I am also deeply engaged in mentoring graduate researchers, leading cross-functional projects, and advancing ethical, robust, and adaptable AI frameworks across computer vision, multimodal learning, and generative technologies.
            </p>
        </div>
    </header>
    <main>
        <div class="news-section">
            <h2>News</h2>
            <ul>
                <li>Our paper "Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models" has been accepted to <span class="venue">AAAI'26</span></li>
                <li>Our paper "SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces" has been accepted to <span class="venue">WACV'26</span></li>
                <li>I have started a new position as Senior AI/ML Scientist at Macquarie University's Silicon Platforms Lab starting from <span class="venue">August 2025</span></li>
                <li>Our paper "LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration" has been accepted to <span class="venue">TMLR'25</span></li>
                <li>Our papers "ETTA: Efficient Test-Time Adaptation for Vision-Language Models" and "Task Progressive Curriculum Learning" have been accepted to <span class="venue">BMVC'25</span></li>
                <li>Our paper "Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models" has been accepted to <span class="venue">WACV'25</span></li>
                <li>Our paper "Canonical shape projection is all you need for 3d few-shot class incremental learning" has been accepted to <span class="venue">ECCV'24</span></li>
                <li>Our paper "Backpropagation-free Network for 3D Test-time Adaptation" has been accepted to <span class="venue">CVPR'24</span></li>
                <li>Our paper "Continual test-time domain adaptation via dynamic sample selection" has been accepted to <span class="venue">WACV'24</span></li>
                <li>Our paper "Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor" has been accepted to <span class="venue">ACCV'24</span></li>
                <li>Our paper "3D Point Cloud Network Pruning: When Some Weights Do not Matter" has been accepted to <span class="venue">BMVC'24</span></li>
                <li>Our paper "3D scene generation for zero-shot learning using ChatGPT guided language prompts" has been accepted to <span class="venue">CVIU'24</span></li>
                <li>Our papers "Efficient Atmospheric Correction" and "Enhancing Glaucoma Diagnosis" have been accepted to <span class="venue">DICTA'24</span></li>
            </ul>
        </div>

        <div class="chatbot-section">
            <h2>ðŸ¤– Ask Me Anything</h2>
            <div class="chatbot-description">
                <p>Have questions about my research, career, or want to know more about my work? Chat with my AI assistant that knows about my background, publications, and expertise. Feel free to ask about my research areas, publications, or any other questions you might have!</p>
            </div>
            <div class="chatbot-container">
                <div class="chatbot-placeholder">
                    <div class="chatbot-icon">ðŸ¤–</div>
                    <h3>Chat with Ali's AI Assistant</h3>
                    <p>Engage with my intelligent AI assistant that has comprehensive knowledge about my research journey, publications, and expertise in AI/ML, computer vision, and generative technologies.</p>
                    
                    <div class="sample-questions">
                        <div class="sample-question">What are your main research areas?</div>
                        <div class="sample-question">Tell me about your publications</div>
                        <div class="sample-question">What's your career journey?</div>
                        <div class="sample-question">How can I collaborate?</div>
                    </div>
                    
                    <a href="https://huggingface.co/spaces/alichr/career_conversation" target="_blank" class="chatbot-launch-button">
                        ðŸš€ Start Conversation
                    </a>
                    
                    <div class="ai-features">
                        <div class="ai-feature">
                            <span class="ai-feature-icon">ðŸ§ </span>
                            <div class="ai-feature-text">Research Expert</div>
                        </div>
                        <div class="ai-feature">
                            <span class="ai-feature-icon">ðŸ“š</span>
                            <div class="ai-feature-text">Publication Knowledge</div>
                        </div>
                        <div class="ai-feature">
                            <span class="ai-feature-icon">ðŸŽ¯</span>
                            <div class="ai-feature-text">Collaboration Ready</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="publications-section">
            <h2>Publications</h2>
            <div class="stats-container">
                <div class="citation-graph">
                    <h3>Citations Over Time</h3>
                    <canvas id="citationChart"></canvas>
                </div>
                <div class="citation-stats">
                    <h3>Citation Metrics</h3>
                    <div class="stat-item">
                        <span class="stat-label">Total Citations</span>
                        <span class="stat-value">925</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">h-index</span>
                        <span class="stat-value">12</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">i10-index</span>
                        <span class="stat-value">13</span>
                    </div>
                </div>
            </div>

            <div class="publications-list">
                <h3>Publications</h3>
                
                <h4>2026</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models.webp" alt="Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="#" target="_blank"><strong>Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models</strong></a><br>
                            Mehran Tamjidi, Hamidreza Dastmalchi, Mohammadreza Alimoradijazi, Ali Cheraghian, Aijun An, Morteza Saberi<br>
                            AAAI 2026
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces.webp" alt="SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="#" target="_blank"><strong>SDMD: Subspace-Driven Model Distillation in Indefinite Inner Product Spaces</strong></a><br>
                            Zeeshan Hayder, Ali Cheraghian, Lars Petersson, Mehrtash Harandi<br>
                            WACV 2026
                        </div>
                    </li>
                </ul>

                <h4>2025</h4>
                <ul>
                    <li>
                        <img src="./images/papers/LumiNet: Perception-Driven Knowledge Distillation.webp" alt="LumiNet paper" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="#" target="_blank"><strong>LumiNet: Perception-Driven Knowledge Distillation via Statistical Logit Calibration</strong></a><br>
                            MI Hossain, MM Lutfe Elahi, S Ramasinghe, A Cheraghian, F Rahman, N Mohammed, S Rahman<br>
                            TMLR 2025
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/ETTA_Efficient Test-Time Adaptation for Vision-Language Models.webp" alt="ETTA paper" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="#" target="_blank"><strong>ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates</strong></a><br>
                            H Dastmalchi, A An, A Cheraghian<br>
                            BMVC 2025
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Task Progressive Curriculum Learning.webp" alt="Task Progressive Curriculum Learning paper" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="#" target="_blank"><strong>Task Progressive Curriculum Learning for Robust Visual Question Answering</strong></a><br>
                            A Akl, A Khamis, Z Wang, A Cheraghian, S Khalifa, K Wang<br>
                            BMVC 2025
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Test_Time_Adaptation_3D_Point_Clouds.webp" alt="Test-Time Adaptation paper" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2411.14495" target="_blank"><strong>Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models</strong></a><br>
                            H Dastmalchi, A An, A Cheraghian, S Rahman, S Ramasinghe<br>
                            WACV 2025
                        </div>
                    </li>
                </ul>

                <h4>2024</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Backpropagation-free_Network_for_3D_Test-time_Adaptation.webp" alt="Backpropagation-free Network for 3D Test-time Adaptation" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Backpropagation-free_Network_for_3D_Test-time_Adaptation_CVPR_2024_paper.pdf" target="_blank"><strong>Backpropagation-free Network for 3D Test-time Adaptation</strong></a><br>
                            Y Wang, A Cheraghian, Z Hayder, J Hong, S Ramasinghe, S Rahman<br>
                            CVPR 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Continual_test-time_domain_adaptation_via_dynamic_sample_selection.webp" alt="Continual test-time domain adaptation via dynamic sample selection" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf" target="_blank"><strong>Continual test-time domain adaptation via dynamic sample selection</strong></a><br>
                            Y Wang, J Hong, A Cheraghian, S Rahman, D Ahmedt-Aristizabal<br>
                            WACV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Canonical_shape_projection_is_all_you_need_for_3d_few-shot_class_incremental_learning.webp" alt="Canonical shape projection is all you need for 3d few-shot class incremental learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05717.pdf" target="_blank"><strong>Canonical shape projection is all you need for 3d few-shot class incremental learning</strong></a><br>
                            A Cheraghian, Z Hayder, S Ramasinghe, S Rahman, J Jafaryahya<br>
                            ECCV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor.webp" alt="Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Ahmadi_Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor_ACCV_2024_paper.pdf" target="_blank"><strong>Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor</strong></a><br>
                            S Ahmadi, A Cheraghian, M Saberi, MT Abir, H Dastmalchi, F Hussain<br>
                            ACCV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3D_Point_Cloud_Network_Pruning_When_Some_Weights_Do_not_Matter.webp" alt="3D Point Cloud Network Pruning When Some Weights Do not Matter" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_637/paper.pdf" target="_blank"><strong>3D Point Cloud Network Pruning: When Some Weights Do not Matter</strong></a><br>
                            A Biswas, MI Hossain, MM Elahi, A Cheraghian, F Rahman<br>
                            BMVC 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3D_scene_generation_for_zero-shot_learning_using_ChatGPT_guided_language_prompts.webp" alt="3D scene generation for zero-shot learning using ChatGPT guided language prompts" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/pii/S1077314224002923" target="_blank"><strong>3D scene generation for zero-shot learning using ChatGPT guided language prompts</strong></a><br>
                            S Ahmadi, A Cheraghian, TF Chowdhury, M Saberi, S Rahman<br>
                            CVIU 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Efficient_Atmospheric_Correction.webp" alt="Atmospheric Correction" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869604" target="_blank"><strong>Efficient Atmospheric Correction for Onboard Processing Using Knowledge Distillation and Model Compression</strong></a><br>
                            M Zhang, A Cheraghian, Y Qin, D Benn, T Rollan, N Habili<br>
                            DICTA 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Enhancing_Glaucoma_Diagnosis.webp" alt="Glaucoma Diagnosis" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869527" target="_blank"><strong>Enhancing Glaucoma Diagnosis through Vision-Language Models and Large Language Model Descriptions</strong></a><br>
                            HY Bae, M Saberi, S Shariflou, M Kalloniatis, J Phu, A Agar, A Cheraghian<br>
                            DICTA 2024
                        </div>
                    </li>
                </ul>

                <h4>2023</h4>
                <ul>
                    <li>
                        <img src="./images/papers/ChatGPT-guided_Semantics_for_Zero-shot_Learning.webp" alt="ChatGPT-guided Semantics for Zero-shot Learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2310.11657" target="_blank"><strong>ChatGPT-guided Semantics for Zero-shot Learning</strong></a><br>
                            FH Shubho, TF Chowdhury, A Cheraghian, M Saberi, N Mohammed<br>
                            DICTA 2023
                        </div>
                    </li>
                </ul>

                <h4>2022</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Zero-shot_learning_on_3d_point_cloud_objects_and_beyond.webp" alt="Zero-shot learning on 3d point cloud objects and beyond" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2104.04980" target="_blank"><strong>Zero-shot learning on 3d point cloud objects and beyond</strong></a><br>
                            A Cheraghian, S Rahman, TF Chowdhury, D Campbell, L Petersson<br>
                            IJCV 2022
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Few-shot_class-incremental_learning_for_3d_point_cloud_objects.webp" alt="Few-shot class-incremental learning for 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800194.pdf" target="_blank"><strong>Few-shot class-incremental learning for 3d point cloud objects</strong></a><br>
                            T Chowdhury, A Cheraghian, S Ramasinghe, S Ahmadi, M Saberi<br>
                            ECCV 2022
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Prompt-guided_scene_generation_for_3d_zero-shot_learning.webp" alt="Prompt-guided scene generation for 3d zero-shot learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2209.14690" target="_blank"><strong>Prompt-guided scene generation for 3d zero-shot learning</strong></a><br>
                            M Nasiri, A Cheraghian, TF Chowdhury, S Ahmadi, M Saberi, S Rahman<br>
                            DICTA 2022
                        </div>
                    </li>
                </ul>

                <h4>2021</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Semantic-aware_knowledge_distillation_for_few-shot_class-incremental_learning.webp" alt="Semantic-aware knowledge distillation for few-shot class-incremental learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf" target="_blank"><strong>Semantic-aware knowledge distillation for few-shot class-incremental learning</strong></a><br>
                            A Cheraghian, S Rahman, P Fang, SK Roy, L Petersson, M Harandi<br>
                            CVPR 2021
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Synthesized_feature_based_few-shot_class-incremental_learning_on_a_mixture_of_subspaces.webp" alt="Synthesized feature based few-shot class-incremental learning on a mixture of subspaces" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cheraghian_Synthesized_Feature_Based_Few-Shot_Class-Incremental_Learning_on_a_Mixture_of_ICCV_2021_paper.pdf" target="_blank"><strong>Synthesized feature based few-shot class-incremental learning on a mixture of subspaces</strong></a><br>
                            A Cheraghian, S Rahman, S Ramasinghe, P Fang, C Simon, L Petersson<br>
                            ICCV 2021
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Learning_without_forgetting_for_3d_point_cloud_objects.webp" alt="Learning without forgetting for 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2106.14275" target="_blank"><strong>Learning without forgetting for 3d point cloud objects</strong></a><br>
                            T Chowdhury, M Jalisha, A Cheraghian, S Rahman<br>
                            IWANN 2021
                        </div>
                    </li>
                </ul>

                <h4>2020</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Transductive_zero-shot_learning_for_3d_point_cloud_classification.webp" alt="Transductive zero-shot learning for 3d point cloud classification" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Cheraghian_Transductive_Zero-Shot_Learning_for_3D_Point_Cloud_Classification_WACV_2020_paper.pdf" target="_blank"><strong>Transductive zero-shot learning for 3d point cloud classification</strong></a><br>
                            A Cheraghian, S Rahman, D Campbell, L Petersson<br>
                            WACV 2020
                        </div>
                    </li>
                </ul>

                <h4>Earlier Publications</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Zero-shot_learning_of_3d_point_cloud_objects.webp" alt="Zero-shot learning of 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/1902.10272" target="_blank"><strong>Zero-shot learning of 3d point cloud objects</strong></a><br>
                            A Cheraghian, S Rahman, L Petersson<br>
                            MVA 2019
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3dcapsule_Extending_the_capsule_architecture_to_classify_3d_point_clouds.webp" alt="3dcapsule Extending the capsule architecture to classify 3d point clouds" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/1811.02191" target="_blank"><strong>3dcapsule: Extending the capsule architecture to classify 3d point clouds</strong></a><br>
                            A Cheraghian, L Petersson<br>
                            WACV 2019
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Surface_geodesic_pattern_for_3D_deformable_texture_matching.webp" alt="Surface geodesic pattern for 3D deformable texture matching" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320316302321" target="_blank"><strong>Surface geodesic pattern for 3D deformable texture matching</strong></a><br>
                            F Hajati, A Cheraghian, S Gheisari, Y Gao, AS Mian<br>
                            Pattern Recognition 2017
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </main>

    <script>
        const ctx = document.getElementById('citationChart').getContext('2d');
        new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ['2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025', '2026'],
                datasets: [{
                    label: 'Citations',
                    data: [3, 5, 8, 25, 44, 113, 207, 228, 270, 11], // Updated 2025 value to 64
                    backgroundColor: [
                        'rgba(255, 99, 132, 0.7)',   // Pink
                        'rgba(54, 162, 235, 0.7)',   // Blue
                        'rgba(255, 206, 86, 0.7)',   // Yellow
                        'rgba(75, 192, 192, 0.7)',   // Teal
                        'rgba(153, 102, 255, 0.7)',  // Purple
                        'rgba(255, 159, 64, 0.7)',   // Orange
                        'rgba(46, 204, 113, 0.7)',   // Green
                        'rgba(142, 68, 173, 0.7)'    // Deep Purple
                    ],
                    borderColor: [
                        'rgb(255, 99, 132)',
                        'rgb(54, 162, 235)',
                        'rgb(255, 206, 86)',
                        'rgb(75, 192, 192)',
                        'rgb(153, 102, 255)',
                        'rgb(255, 159, 64)',
                        'rgb(46, 204, 113)',
                        'rgb(142, 68, 173)'
                    ],
                    borderWidth: 1,
                    borderRadius: 5,
                    hoverBackgroundColor: [
                        'rgba(255, 99, 132, 0.9)',
                        'rgba(54, 162, 235, 0.9)',
                        'rgba(255, 206, 86, 0.9)',
                        'rgba(75, 192, 192, 0.9)',
                        'rgba(153, 102, 255, 0.9)',
                        'rgba(255, 159, 64, 0.9)',
                        'rgba(46, 204, 113, 0.9)',
                        'rgba(142, 68, 173, 0.9)'
                    ]
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        display: false
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        grid: {
                            color: 'rgba(0, 0, 0, 0.05)'
                        },
                        ticks: {
                            font: {
                                family: 'Montserrat'
                            }
                        }
                    },
                    x: {
                        grid: {
                            display: false
                        },
                        ticks: {
                            font: {
                                family: 'Montserrat'
                            }
                        }
                    }
                },
                animation: {
                    duration: 2000,
                    easing: 'easeInOutQuart'
                },
                hover: {
                    mode: 'nearest',
                    intersect: true
                }
            }
        });

        // Function to fetch citation data from Google Scholar
        async function updateCitationData() {
            try {
                const response = await fetch('https://scholar.google.com/citations?user=QT0EXIkAAAAJ&hl=en');
                // Parse the response and update chart data
                // Note: You'll need a backend service to handle CORS and data scraping
            } catch (error) {
                console.error('Error fetching citation data:', error);
            }
        }

        // Interactive sample questions for chatbot
        document.addEventListener('DOMContentLoaded', function() {
            const sampleQuestions = document.querySelectorAll('.sample-question');
            const chatbotButton = document.querySelector('.chatbot-launch-button');
            
            sampleQuestions.forEach(question => {
                question.addEventListener('click', function() {
                    // Add a subtle animation when clicked
                    this.style.transform = 'scale(0.95)';
                    this.style.background = 'rgba(255, 255, 255, 0.4)';
                    
                    setTimeout(() => {
                        this.style.transform = '';
                        this.style.background = '';
                    }, 150);
                    
                    // Open the chatbot with the question (you could enhance this further)
                    setTimeout(() => {
                        window.open(chatbotButton.href, '_blank');
                    }, 200);
                });
            });

            // Add typing animation effect to the chatbot icon
            const chatbotIcon = document.querySelector('.chatbot-icon');
            if (chatbotIcon) {
                setInterval(() => {
                    chatbotIcon.style.filter = 'drop-shadow(0 4px 8px rgba(0, 0, 0, 0.3)) brightness(1.1)';
                    setTimeout(() => {
                        chatbotIcon.style.filter = 'drop-shadow(0 4px 8px rgba(0, 0, 0, 0.3))';
                    }, 500);
                }, 3000);
            }
        });
    </script>
    
    <!-- Simple and reliable visitor counter using FlagCounter -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Create container for counter
            const counterContainer = document.createElement('div');
            counterContainer.style.position = 'fixed';
            counterContainer.style.bottom = '10px';
            counterContainer.style.right = '10px';
            counterContainer.style.background = 'rgba(255, 255, 255, 0.95)';
            counterContainer.style.padding = '8px 12px';
            counterContainer.style.borderRadius = '8px';
            counterContainer.style.boxShadow = '0 2px 8px rgba(0, 0, 0, 0.1)';
            counterContainer.style.fontFamily = 'Montserrat, sans-serif';
            counterContainer.style.zIndex = '1000';
            counterContainer.style.display = 'flex';
            counterContainer.style.flexDirection = 'column';
            counterContainer.style.alignItems = 'center';
            
            // Simple flag counter - a proven solution
            counterContainer.innerHTML = '<div style="font-size:12px;color:#666;font-weight:500;margin-bottom:4px">Visitors:</div>' +
                '<a href="https://info.flagcounter.com/8m5j">' +
                '<img src="https://s11.flagcounter.com/mini/8m5j/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" ' +
                'alt="Visitor Counter" style="border:0;">' +
                '</a>';
            
            document.body.appendChild(counterContainer);
        });
    </script>
</body>

</html>