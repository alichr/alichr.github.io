<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Ali Cheraghian - Research Scientist specializing in AI, Machine Learning, and Computer Vision">
    <title>Ali Cheraghian - Research Scientist</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {
            --primary-color: #002b5e;
            --secondary-color: #a7c5ed;
            --text-color: #333;
            --bg-color: #f0f4f8;
            --card-bg: #fff;
            --hover-color: #003875;
        }

        body {
            font-family: 'Montserrat', sans-serif;
            margin: 0;
            padding: 0;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
        }

        header {
            background: var(--primary-color);
            color: #fff;
            padding: 3rem 0;
            position: relative;
            overflow: hidden;
        }

        header::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: var(--secondary-color);
        }

        .header-content {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            text-align: center;
        }

        header h1 {
            font-size: 3rem;
            margin: 0;
            letter-spacing: 1px;
        }

        header .title {
            font-size: 1.4rem;
            margin: 1rem 0;
            color: var(--secondary-color);
        }

        .contact-links {
            margin: 1.5rem 0;
        }

        .contact-links a {
            color: var(--secondary-color);
            text-decoration: none;
            margin: 0 1rem;
            padding: 0.5rem 1rem;
            border: 1px solid var(--secondary-color);
            border-radius: 4px;
            transition: all 0.3s ease;
        }

        .contact-links a:hover {
            background: var(--secondary-color);
            color: var(--primary-color);
        }

        .profile-photo {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            margin: 0 auto 2rem;
            display: block;
            border: 4px solid var(--secondary-color);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            object-fit: cover;
        }

        @media (max-width: 768px) {
            .profile-photo {
                width: 150px;
                height: 150px;
            }
        }

        .contact-info {
            max-width: 800px;
            margin: 2rem auto;
            text-align: center;
            color: var(--secondary-color);
            font-size: 1.1rem;
            line-height: 1.8;
        }

        .contact-info p {
            margin: 0.5rem 0;
        }

        .news-section {
            max-width: 800px;
            margin: 3rem auto;
            text-align: left;
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .news-section h2 {
            text-align: left;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
            font-size: 1.5rem;
            position: relative;
            padding-bottom: 0.5rem;
        }

        .news-section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 40px;
            height: 2px;
            background: var(--secondary-color);
        }

        .news-section ul {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }

        .news-section li {
            position: relative;
            padding: 0.8rem 0;
            margin-bottom: 0.5rem;
            color: var(--text-color);
            font-size: 0.95rem;
            line-height: 1.6;
            border-bottom: 1px solid rgba(0, 43, 94, 0.1);
        }

        .news-section li:last-child {
            border-bottom: none;
        }

        .news-section li:before {
            content: "â€¢";
            position: absolute;
            left: -1rem;
            color: var(--primary-color);
        }

        .news-section a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s ease;
        }

        .news-section a:hover {
            color: var(--hover-color);
        }

        main {
            padding: 2rem;
            max-width: 1200px;
            margin: 0 auto;
        }

        .stats-container {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 2rem;
            margin-top: 2rem;
        }

        .citation-graph {
            flex: 1;
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
            height: 300px;
        }

        .citation-graph h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .citation-stats {
            flex: 1;
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .citation-stats h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .stat-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.8rem;
            padding-bottom: 0.8rem;
            border-bottom: 1px solid rgba(0, 43, 94, 0.1);
        }

        .stat-item:last-child {
            border-bottom: none;
        }

        .stat-label {
            color: var(--text-color);
            font-size: 0.95rem;
        }

        .stat-value {
            color: var(--primary-color);
            font-weight: 600;
        }

        .publications-section {
            max-width: 1200px;
            margin: 3rem auto;
            text-align: left;
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .publications-section h2 {
            text-align: left;
            margin-bottom: 1.5rem;
            color: var(--primary-color);
            font-size: 1.5rem;
            position: relative;
            padding-bottom: 0.5rem;
        }

        .publications-section h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 40px;
            height: 2px;
            background: var(--secondary-color);
        }

        .publications-list {
            margin-top: 2rem;
        }

        .publications-list h3 {
            color: var(--primary-color);
            font-size: 1.2rem;
            margin-bottom: 1rem;
        }

        .publications-list h4 {
            color: var(--primary-color);
            font-size: 1.3rem;
            margin: 2rem 0 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--secondary-color);
        }

        .publications-list h4:first-child {
            margin-top: 0;
        }

        .publications-list ul {
            margin-bottom: 1rem;
        }

        .publications-list ul:last-child {
            margin-bottom: 0;
        }

        .publications-list li {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
            align-items: flex-start;
        }

        .publication-thumbnail {
            width: 120px;
            height: 80px;
            object-fit: contain;
            background-color: transparent;
            padding: 0;
            margin: 0;
            display: block;
        }

        .publication-content {
            flex: 1;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
        }

        .publication-content strong {
            color: var(--primary-color);
            font-size: 1.1rem;
            margin-bottom: 0.3rem;
            line-height: 1.3;
        }

        /* Remove underline from paper title links */
        .publication-content a {
            text-decoration: none;
        }

        .publication-content br + text {
            font-size: 0.9rem;
            color: var(--text-color);
            opacity: 0.9;
        }

        /* Add this new CSS rule for venue highlighting */
        .venue {
            color: var(--primary-color);
            font-weight: 600;
        }

        /* Add this new CSS rule after existing styles */
        .visit-counter {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.95);
            padding: 12px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            font-family: 'Montserrat', sans-serif;
            z-index: 1000;
            width: 200px;
        }

        .visit-counter .graph-container {
            height: 100px;
        }
    </style>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>

<body>
    <div class="visit-counter">
        <div class="graph-container">
            <canvas id="visitorChart"></canvas>
        </div>
    </div>
    <header>
        <div class="header-content">
            <img src="./images/profile.webp" alt="Ali Cheraghian" class="profile-photo" loading="lazy">
            <h1>Ali Cheraghian</h1>
            <div class="title">AI/ML/CV Scientist at CSIRO Data61 | Adjunct Faculty at ANU | AI/ML/CV Engineer</div>
            <div class="contact-links">
                <a href="mailto:ali.cheraghian@data61.csiro.au">Email</a>
                <a href="https://www.linkedin.com/in/ali-cheraghian/" target="_blank">LinkedIn</a>
                <a href="https://github.com/alichr" target="_blank">GitHub</a>
                <a href="https://scholar.google.com/citations?user=QT0EXIkAAAAJ" target="_blank">Google Scholar</a>
            </div>
            <p style="max-width: 800px; margin: 2rem auto; line-height: 1.8; text-align: justify;">
                As a Scientist at CSIRO Data61, Adjunct Faculty Member at the Australian National University (ANU), and AI/ML/CV engineer, I specialize in large vision-language models (VLMs), large language models (LLMs), generative AI, knowledge distillation, and incremental learning. With extensive engineering experience, I design and deploy scalable AI/ML solutions that bridge cutting-edge research (e.g., publications in top-tier conferences, IP development) with real-world industrial applications, while mentoring graduate researchers and leading cross-functional projects. My work spans both academia and industry, emphasizing ethical innovation, robust system design, and adaptable frameworks for computer vision, multimodal AI, and generative technologies.
            </p>
        </div>
    </header>
    <main>
        <div class="news-section">
            <h2>News</h2>
            <ul>
                <li>Our paper "Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models" has been accepted to <span class="venue">WACV'25</span></li>
                <li>Our paper "Canonical shape projection is all you need for 3d few-shot class incremental learning" has been accepted to <span class="venue">ECCV'24</span></li>
                <li>Our paper "Backpropagation-free Network for 3D Test-time Adaptation" has been accepted to <span class="venue">CVPR'24</span></li>
                <li>Our paper "Continual test-time domain adaptation via dynamic sample selection" has been accepted to <span class="venue">WACV'24</span></li>
                <li>Our paper "Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor" has been accepted to <span class="venue">ACCV'24</span></li>
                <li>Our paper "3D Point Cloud Network Pruning: When Some Weights Do not Matter" has been accepted to <span class="venue">BMVC'24</span></li>
                <li>Our paper "3D scene generation for zero-shot learning using ChatGPT guided language prompts" has been accepted to <span class="venue">CVIU'24</span></li>
                <li>Our papers "Efficient Atmospheric Correction" and "Enhancing Glaucoma Diagnosis" have been accepted to <span class="venue">DICTA'24</span></li>
            </ul>
        </div>

        <div class="publications-section">
            <h2>Publications</h2>
            <div class="stats-container">
                <div class="citation-graph">
                    <h3>Citations Over Time</h3>
                    <canvas id="citationChart"></canvas>
                </div>
                <div class="citation-stats">
                    <h3>Citation Metrics</h3>
                    <div class="stat-item">
                        <span class="stat-label">Total Citations</span>
                        <span class="stat-value">726</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">h-index</span>
                        <span class="stat-value">11</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">i10-index</span>
                        <span class="stat-value">11</span>
                    </div>
                </div>
            </div>

            <div class="publications-list">
                <h3>Publications</h3>
                
                <h4>2025</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Test_Time_Adaptation_3D_Point_Clouds.webp" alt="Test-Time Adaptation paper" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2411.14495" target="_blank"><strong>Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models</strong></a><br>
                            H Dastmalchi, A An, A Cheraghian, S Rahman, S Ramasinghe<br>
                            WACV 2025
                        </div>
                    </li>
                </ul>

                <h4>2024</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Backpropagation-free_Network_for_3D_Test-time_Adaptation.webp" alt="Backpropagation-free Network for 3D Test-time Adaptation" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Backpropagation-free_Network_for_3D_Test-time_Adaptation_CVPR_2024_paper.pdf" target="_blank"><strong>Backpropagation-free Network for 3D Test-time Adaptation</strong></a><br>
                            Y Wang, A Cheraghian, Z Hayder, J Hong, S Ramasinghe, S Rahman<br>
                            CVPR 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Continual_test-time_domain_adaptation_via_dynamic_sample_selection.webp" alt="Continual test-time domain adaptation via dynamic sample selection" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf" target="_blank"><strong>Continual test-time domain adaptation via dynamic sample selection</strong></a><br>
                            Y Wang, J Hong, A Cheraghian, S Rahman, D Ahmedt-Aristizabal<br>
                            WACV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Canonical_shape_projection_is_all_you_need_for_3d_few-shot_class_incremental_learning.webp" alt="Canonical shape projection is all you need for 3d few-shot class incremental learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05717.pdf" target="_blank"><strong>Canonical shape projection is all you need for 3d few-shot class incremental learning</strong></a><br>
                            A Cheraghian, Z Hayder, S Ramasinghe, S Rahman, J Jafaryahya<br>
                            ECCV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor.webp" alt="Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ACCV2024/papers/Ahmadi_Foundation_Model-Powered_3D_Few-Shot_Class_Incremental_Learning_via_Training-free_Adaptor_ACCV_2024_paper.pdf" target="_blank"><strong>Foundation Model-Powered 3D Few-Shot Class Incremental Learning via Training-free Adaptor</strong></a><br>
                            S Ahmadi, A Cheraghian, M Saberi, MT Abir, H Dastmalchi, F Hussain<br>
                            ACCV 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3D_Point_Cloud_Network_Pruning_When_Some_Weights_Do_not_Matter.webp" alt="3D Point Cloud Network Pruning When Some Weights Do not Matter" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_637/paper.pdf" target="_blank"><strong>3D Point Cloud Network Pruning: When Some Weights Do not Matter</strong></a><br>
                            A Biswas, MI Hossain, MM Elahi, A Cheraghian, F Rahman<br>
                            BMVC 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3D_scene_generation_for_zero-shot_learning_using_ChatGPT_guided_language_prompts.webp" alt="3D scene generation for zero-shot learning using ChatGPT guided language prompts" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/pii/S1077314224002923" target="_blank"><strong>3D scene generation for zero-shot learning using ChatGPT guided language prompts</strong></a><br>
                            S Ahmadi, A Cheraghian, TF Chowdhury, M Saberi, S Rahman<br>
                            CVIU 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Efficient_Atmospheric_Correction.webp" alt="Atmospheric Correction" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869604" target="_blank"><strong>Efficient Atmospheric Correction for Onboard Processing Using Knowledge Distillation and Model Compression</strong></a><br>
                            M Zhang, A Cheraghian, Y Qin, D Benn, T Rollan, N Habili<br>
                            DICTA 2024
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Enhancing_Glaucoma_Diagnosis.webp" alt="Glaucoma Diagnosis" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://ieeexplore.ieee.org/document/10869527" target="_blank"><strong>Enhancing Glaucoma Diagnosis through Vision-Language Models and Large Language Model Descriptions</strong></a><br>
                            HY Bae, M Saberi, S Shariflou, M Kalloniatis, J Phu, A Agar, A Cheraghian<br>
                            DICTA 2024
                        </div>
                    </li>
                </ul>

                <h4>2023</h4>
                <ul>
                    <li>
                        <img src="./images/papers/ChatGPT-guided_Semantics_for_Zero-shot_Learning.webp" alt="ChatGPT-guided Semantics for Zero-shot Learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2310.11657" target="_blank"><strong>ChatGPT-guided Semantics for Zero-shot Learning</strong></a><br>
                            FH Shubho, TF Chowdhury, A Cheraghian, M Saberi, N Mohammed<br>
                            DICTA 2023
                        </div>
                    </li>
                </ul>

                <h4>2022</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Zero-shot_learning_on_3d_point_cloud_objects_and_beyond.webp" alt="Zero-shot learning on 3d point cloud objects and beyond" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2104.04980" target="_blank"><strong>Zero-shot learning on 3d point cloud objects and beyond</strong></a><br>
                            A Cheraghian, S Rahman, TF Chowdhury, D Campbell, L Petersson<br>
                            IJCV 2022
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Few-shot_class-incremental_learning_for_3d_point_cloud_objects.webp" alt="Few-shot class-incremental learning for 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800194.pdf" target="_blank"><strong>Few-shot class-incremental learning for 3d point cloud objects</strong></a><br>
                            T Chowdhury, A Cheraghian, S Ramasinghe, S Ahmadi, M Saberi<br>
                            ECCV 2022
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Prompt-guided_scene_generation_for_3d_zero-shot_learning.webp" alt="Prompt-guided scene generation for 3d zero-shot learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2209.14690" target="_blank"><strong>Prompt-guided scene generation for 3d zero-shot learning</strong></a><br>
                            M Nasiri, A Cheraghian, TF Chowdhury, S Ahmadi, M Saberi, S Rahman<br>
                            DICTA 2022
                        </div>
                    </li>
                </ul>

                <h4>2021</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Semantic-aware_knowledge_distillation_for_few-shot_class-incremental_learning.webp" alt="Semantic-aware knowledge distillation for few-shot class-incremental learning" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.pdf" target="_blank"><strong>Semantic-aware knowledge distillation for few-shot class-incremental learning</strong></a><br>
                            A Cheraghian, S Rahman, P Fang, SK Roy, L Petersson, M Harandi<br>
                            CVPR 2021
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Synthesized_feature_based_few-shot_class-incremental_learning_on_a_mixture_of_subspaces.webp" alt="Synthesized feature based few-shot class-incremental learning on a mixture of subspaces" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cheraghian_Synthesized_Feature_Based_Few-Shot_Class-Incremental_Learning_on_a_Mixture_of_ICCV_2021_paper.pdf" target="_blank"><strong>Synthesized feature based few-shot class-incremental learning on a mixture of subspaces</strong></a><br>
                            A Cheraghian, S Rahman, S Ramasinghe, P Fang, C Simon, L Petersson<br>
                            ICCV 2021
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Learning_without_forgetting_for_3d_point_cloud_objects.webp" alt="Learning without forgetting for 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/2106.14275" target="_blank"><strong>Learning without forgetting for 3d point cloud objects</strong></a><br>
                            T Chowdhury, M Jalisha, A Cheraghian, S Rahman<br>
                            IWANN 2021
                        </div>
                    </li>
                </ul>

                <h4>2020</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Transductive_zero-shot_learning_for_3d_point_cloud_classification.webp" alt="Transductive zero-shot learning for 3d point cloud classification" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://openaccess.thecvf.com/content_WACV_2020/papers/Cheraghian_Transductive_Zero-Shot_Learning_for_3D_Point_Cloud_Classification_WACV_2020_paper.pdf" target="_blank"><strong>Transductive zero-shot learning for 3d point cloud classification</strong></a><br>
                            A Cheraghian, S Rahman, D Campbell, L Petersson<br>
                            WACV 2020
                        </div>
                    </li>
                </ul>

                <h4>Earlier Publications</h4>
                <ul>
                    <li>
                        <img src="./images/papers/Zero-shot_learning_of_3d_point_cloud_objects.webp" alt="Zero-shot learning of 3d point cloud objects" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/1902.10272" target="_blank"><strong>Zero-shot learning of 3d point cloud objects</strong></a><br>
                            A Cheraghian, S Rahman, L Petersson<br>
                            MVA 2019
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/3dcapsule_Extending_the_capsule_architecture_to_classify_3d_point_clouds.webp" alt="3dcapsule Extending the capsule architecture to classify 3d point clouds" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://arxiv.org/pdf/1811.02191" target="_blank"><strong>3dcapsule: Extending the capsule architecture to classify 3d point clouds</strong></a><br>
                            A Cheraghian, L Petersson<br>
                            WACV 2019
                        </div>
                    </li>
                    <li>
                        <img src="./images/papers/Surface_geodesic_pattern_for_3D_deformable_texture_matching.webp" alt="Surface geodesic pattern for 3D deformable texture matching" class="publication-thumbnail" loading="lazy">
                        <div class="publication-content">
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320316302321" target="_blank"><strong>Surface geodesic pattern for 3D deformable texture matching</strong></a><br>
                            F Hajati, A Cheraghian, S Gheisari, Y Gao, AS Mian<br>
                            Pattern Recognition 2017
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </main>

    <script>
        const ctx = document.getElementById('citationChart').getContext('2d');
        new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ['2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025'],
                datasets: [{
                    label: 'Citations',
                    data: [5, 8, 26, 43, 120, 208, 236, 66], // Updated 2025 value to 64
                    backgroundColor: [
                        'rgba(255, 99, 132, 0.7)',   // Pink
                        'rgba(54, 162, 235, 0.7)',   // Blue
                        'rgba(255, 206, 86, 0.7)',   // Yellow
                        'rgba(75, 192, 192, 0.7)',   // Teal
                        'rgba(153, 102, 255, 0.7)',  // Purple
                        'rgba(255, 159, 64, 0.7)',   // Orange
                        'rgba(46, 204, 113, 0.7)',   // Green
                        'rgba(142, 68, 173, 0.7)'    // Deep Purple
                    ],
                    borderColor: [
                        'rgb(255, 99, 132)',
                        'rgb(54, 162, 235)',
                        'rgb(255, 206, 86)',
                        'rgb(75, 192, 192)',
                        'rgb(153, 102, 255)',
                        'rgb(255, 159, 64)',
                        'rgb(46, 204, 113)',
                        'rgb(142, 68, 173)'
                    ],
                    borderWidth: 1,
                    borderRadius: 5,
                    hoverBackgroundColor: [
                        'rgba(255, 99, 132, 0.9)',
                        'rgba(54, 162, 235, 0.9)',
                        'rgba(255, 206, 86, 0.9)',
                        'rgba(75, 192, 192, 0.9)',
                        'rgba(153, 102, 255, 0.9)',
                        'rgba(255, 159, 64, 0.9)',
                        'rgba(46, 204, 113, 0.9)',
                        'rgba(142, 68, 173, 0.9)'
                    ]
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        display: false
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        grid: {
                            color: 'rgba(0, 0, 0, 0.05)'
                        },
                        ticks: {
                            font: {
                                family: 'Montserrat'
                            }
                        }
                    },
                    x: {
                        grid: {
                            display: false
                        },
                        ticks: {
                            font: {
                                family: 'Montserrat'
                            }
                        }
                    }
                },
                animation: {
                    duration: 2000,
                    easing: 'easeInOutQuart'
                },
                hover: {
                    mode: 'nearest',
                    intersect: true
                }
            }
        });

        // Function to fetch citation data from Google Scholar
        async function updateCitationData() {
            try {
                const response = await fetch('https://scholar.google.com/citations?user=QT0EXIkAAAAJ&hl=en');
                // Parse the response and update chart data
                // Note: You'll need a backend service to handle CORS and data scraping
                chart.data.datasets[0].data = newData;
                chart.update();
            } catch (error) {
                console.error('Error fetching citation data:', error);
            }
        }

        // Update data periodically
        setInterval(updateCitationData, 3600000); // Update every hour
        updateCitationData(); // Initial update

        // Function to get the last 7 days
        function getLast7Days() {
            const days = [];
            for (let i = 6; i >= 0; i--) {
                const date = new Date();
                date.setDate(date.getDate() - i);
                days.push(date.toLocaleDateString('en-US', { weekday: 'short' }));
            }
            return days;
        }

        // Initialize visitor chart
        const visitorCtx = document.getElementById('visitorChart').getContext('2d');
        const visitorChart = new Chart(visitorCtx, {
            type: 'line',
            data: {
                labels: getLast7Days(),
                datasets: [{
                    data: [0, 0, 0, 0, 0, 0, 0],
                    borderColor: 'rgba(0, 43, 94, 0.8)',
                    backgroundColor: 'rgba(0, 43, 94, 0.1)',
                    tension: 0.4,
                    fill: true,
                    pointRadius: 0,
                    borderWidth: 2
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: {
                        display: false
                    },
                    tooltip: {
                        enabled: false
                    }
                },
                scales: {
                    y: {
                        display: false,
                        beginAtZero: true
                    },
                    x: {
                        display: false
                    }
                },
                interaction: {
                    intersect: false,
                    mode: 'index'
                }
            }
        });

        // Function to update visitor data
        function updateVisitorData() {
            const today = new Date().toLocaleDateString();
            let visitorData = JSON.parse(localStorage.getItem('visitorData') || '{}');
            
            if (!visitorData[today]) {
                visitorData[today] = 0;
            }
            visitorData[today]++;
            
            localStorage.setItem('visitorData', JSON.stringify(visitorData));
            
            // Update chart data
            const last7Days = [];
            for (let i = 6; i >= 0; i--) {
                const date = new Date();
                date.setDate(date.getDate() - i);
                const dateStr = date.toLocaleDateString();
                last7Days.push(visitorData[dateStr] || 0);
            }
            
            visitorChart.data.datasets[0].data = last7Days;
            visitorChart.update();
        }

        // Update visitor data on page load
        updateVisitorData();
    </script>
</body>

</html>